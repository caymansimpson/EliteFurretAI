import os
import torch
import threading
import queue
import asyncio
import time
import copy
import numpy as np
from typing import List

from elitefurretai.rl2.agent import RNaDAgent
from elitefurretai.rl2.learner import RNaDLearner
from elitefurretai.rl2.worker import BatchInferencePlayer
from elitefurretai.agents.behavior_clone_player import FlexibleThreeHeadedModel
from elitefurretai.model_utils.embedder import Embedder
from elitefurretai.model_utils.encoder import MDBO
from poke_env.player import RandomPlayer, PlayerConfiguration, ServerConfiguration

# Configuration
CHECKPOINT_PATH = "data/models/bc_action_model.pt" 
VICTIM_PATH = "data/models/victim_model.pt" # The model to exploit
NUM_WORKERS = 4
PLAYERS_PER_WORKER = 4
BATCH_SIZE = 16
LR = 1e-4
RNAD_ALPHA = 0.0 # No regularization for exploiter
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
TRAIN_BATCH_SIZE = 32 

# Reuse load_model and collate_trajectories from train.py
from elitefurretai.rl2.train import load_model, collate_trajectories

def worker_loop(model: RNaDAgent, victim_model: RNaDAgent, traj_queue: queue.Queue, num_players: int, worker_id: int):
    """
    Runs an asyncio loop for a set of players battling a victim model.
    """
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    players = []
    victims = []
    
    for i in range(num_players):
        # Exploiter
        player = BatchInferencePlayer(
            model=model,
            device=DEVICE,
            batch_size=BATCH_SIZE,
            player_configuration=PlayerConfiguration(f"Exploiter_{worker_id}_{i}", None),
            server_configuration=ServerConfiguration("localhost:8000", None),
            trajectory_queue=traj_queue
        )
        players.append(player)
        
        # Victim (Frozen)
        victim = BatchInferencePlayer(
            model=victim_model,
            device=DEVICE,
            batch_size=BATCH_SIZE,
            player_configuration=PlayerConfiguration(f"Victim_{worker_id}_{i}", None),
            server_configuration=ServerConfiguration("localhost:8000", None),
            probabilistic=True # Victim should be stochastic? Or deterministic? Usually stochastic.
        )
        victims.append(victim)
        
    # Start inference loops
    for p in players:
        loop.create_task(p.start_inference_loop())
    for v in victims:
        loop.create_task(v.start_inference_loop())
        
    async def run_battles():
        tasks = []
        for p, v in zip(players, victims):
            tasks.append(p.battle_against(v, n_battles=100000))
        await asyncio.gather(*tasks)
        
    try:
        loop.run_until_complete(run_battles())
    except Exception as e:
        print(f"Worker {worker_id} crashed: {e}")

def main():
    print("Initializing Exploiter Training...")
    
    # Load models
    base_model = load_model(CHECKPOINT_PATH, DEVICE)
    agent = RNaDAgent(base_model)
    
    victim_base_model = load_model(VICTIM_PATH, DEVICE)
    victim_agent = RNaDAgent(victim_base_model)
    # Freeze victim
    for param in victim_agent.parameters():
        param.requires_grad = False
    
    # Ref model is just a dummy here since alpha=0, but learner expects it
    ref_agent = RNaDAgent(copy.deepcopy(base_model))
    
    learner = RNaDLearner(agent, ref_agent, lr=LR, rnad_alpha=RNAD_ALPHA, device=DEVICE)
    
    traj_queue = queue.Queue()
    
    # Start workers
    threads = []
    for i in range(NUM_WORKERS):
        t = threading.Thread(target=worker_loop, args=(agent, victim_agent, traj_queue, PLAYERS_PER_WORKER, i))
        t.daemon = True
        t.start()
        threads.append(t)
        
    print(f"Started {NUM_WORKERS} workers.")
    
    # Training loop (same as train.py)
    trajectories = []
    updates = 0
    
    try:
        while True:
            try:
                traj = traj_queue.get(timeout=1.0)
                trajectories.append(traj)
            except queue.Empty:
                continue
                
            if len(trajectories) >= TRAIN_BATCH_SIZE:
                batch = collate_trajectories(trajectories, DEVICE)
                metrics = learner.update(batch)
                updates += 1
                
                if updates % 10 == 0:
                    print(f"Update {updates}: {metrics}")
                    
                trajectories = []
                
    except KeyboardInterrupt:
        print("Stopping...")

if __name__ == "__main__":
    main()
